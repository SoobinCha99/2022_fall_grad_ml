{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import pprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_name):\n",
    "    \"\"\"\n",
    "    Load json file\n",
    "    :param file_name: file name\n",
    "    :return: loaded data from the file\n",
    "    \"\"\"\n",
    "    with codecs.open(file_name, \"r\", \"utf-8\") as json_f:\n",
    "        return json.load(json_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(dataset):\n",
    "    \"\"\"\n",
    "    Extract sentences and their labels from dataset\n",
    "    - human_sentence: list of the first human utterance in a conversation\n",
    "    - emotion_label: list of the emotion label.\n",
    "    The range of the emotion label is 0 to 5\n",
    "    0: 분노\n",
    "    1: 슬픔\n",
    "    2: 불안\n",
    "    3: 상처\n",
    "    4: 당황\n",
    "    5: 기쁨\n",
    "    :param dataset: loaded data from load_json function\n",
    "    :return: human_sentences and their emotion labels\n",
    "    \"\"\"\n",
    "    \n",
    "    human_sentence = list()\n",
    "    emotion_label = list()\n",
    "\n",
    "    for i in range(0,len(dataset)): \n",
    "        human_sentence.append(dataset[i]['talk']['content']['HS01'])\n",
    "        label = dataset[i]['profile']['emotion']['type']\n",
    "        emotion_label.append(int([*label][1])-1)\n",
    "\n",
    "    #pass    # Task 1\n",
    "\n",
    "    return human_sentence, emotion_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(file_name, sentences, labels):\n",
    "    \"\"\"\n",
    "    Save the sentences and labels to csv file\n",
    "    Header is needed to identify the column\n",
    "\n",
    "    :param file_name: output file name\n",
    "    :param sentences: human sentences from extract_data function\n",
    "    :param labels: emotion labels from extract_data function\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[\"sentence\"] = sentences\n",
    "    temp_df[\"label\"] = labels\n",
    "\n",
    "    temp_df.to_csv(file_name,index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Entry of the program\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    training_data_json_filename = \"./data/train/감성대화말뭉치(최종데이터)_Training.json\"\n",
    "    test_data_json_filename = \"./data/validataion/감성대화말뭉치(최종데이터)_Validation.json\"\n",
    "\n",
    "    training_data_csv_filename = \"./processed_data/train.csv\"\n",
    "    valid_data_csv_filename = \"./processed_data/valid.csv\"\n",
    "    test_data_csv_filename = \"./processed_data/test.csv\"\n",
    "\n",
    "    test_size = 0.1\n",
    "    random_state = 108\n",
    "\n",
    "    # 1. Load json files\n",
    "    training_data = load_json(training_data_json_filename)\n",
    "    test_data = load_json(test_data_json_filename)\n",
    "    #pprint.pprint(training_data[0])\n",
    "    #print()\n",
    "\n",
    "    # 2. Extract data\n",
    "    training_sentences, training_labels = extract_data(training_data)\n",
    "    test_sentences, test_labels = extract_data(test_data)\n",
    "\n",
    "    # 3. Split training data to training and valid data\n",
    "    # Task 3\n",
    "    # Use train_test_split function\n",
    "    # Use test_size and random_state values to split the dataset\n",
    "    '''training_sentences = None\n",
    "    valid_sentences = None\n",
    "    training_labels = None\n",
    "    valid_labels = None'''\n",
    "\n",
    "    training_sentences, valid_sentences, training_labels, valid_labels = train_test_split(training_sentences, training_labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    print(\"# training data: \", len(training_sentences))\n",
    "    print(\"# validation data: \", len(valid_sentences))\n",
    "    print(\"# test data: \", len(test_sentences))\n",
    "\n",
    "    # 4. Save data to csv file\n",
    "    save_csv(training_data_csv_filename, training_sentences, training_labels)\n",
    "    save_csv(valid_data_csv_filename, valid_sentences, valid_labels)\n",
    "    save_csv(test_data_csv_filename, test_sentences, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profile': {'emotion': {'emotion-id': 'S05_D02_E68',\n",
      "                         'situation': ['S05', 'D02'],\n",
      "                         'type': 'E68'},\n",
      "             'persona': {'computer': ['C01'],\n",
      "                         'human': ['A02', 'G01'],\n",
      "                         'persona-id': 'A02_G01_C01'},\n",
      "             'persona-id': 'Pro_03719'},\n",
      " 'talk': {'content': {'HS01': '아내가 드디어 출산하게 되어서 정말 신이 나.',\n",
      "                      'HS02': '아 지금 정말 신이 나.',\n",
      "                      'HS03': '아기가 점점 클게 벌써 기대가 되네. 내가 많이 놀아줘야지. ',\n",
      "                      'SS01': '아내분이 출산을 하시는군요. 정말 축하드려요.',\n",
      "                      'SS02': '잘 된 일이네요.',\n",
      "                      'SS03': '좋은 아빠가 되실 거 같아요. 진심으로 축하드려요.'},\n",
      "          'id': {'profile-id': 'Pro_03719', 'talk-id': 'Pro_03719_00016'}}}\n",
      "\n",
      "# training data:  36744\n",
      "# validation data:  4083\n",
      "# test data:  5122\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d5f8d486bd050c94a6e9429297e6669528901ab188ae91bafb7a9ea614fd771"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
